{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline: Web Scraping Real Estate Data (BuyRentKenya)\n",
    "\n",
    "This notebook demonstrates a complete Extract, Transform, Load (ETL) pipeline using Python:\n",
    "\n",
    "1.  **Extract (Scraping):** Fetches property listings from a real estate website using `requests` and `BeautifulSoup`.\n",
    "2.  **Transform (Cleaning):** Cleans and converts raw text data (like price, bedrooms, and size) into numeric formats using `pandas` and `re`.\n",
    "3.  **Load (Database):** Inserts the cleaned data into a PostgreSQL database using `SQLAlchemy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install beautifulsoup4 pandas requests sqlalchemy psycopg2-binary --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import time\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, Column, Integer, Float, String, DateTime, Text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import inspect\n",
    "from datetime import datetime\n",
    "\n",
    "def scrape_pages(start_page: int, end_page: int) -> pd.DataFrame:\n",
    "    \"\"\"Scrapes property listings from a range of BuyRentKenya pages.\"\"\"\n",
    "    base_url = 'https://www.buyrentkenya.com/houses-for-sale'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                      '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "    }\n",
    "    properties = []\n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        url = f'{base_url}?page={page_num}'\n",
    "        print(f\"\\nüîç Scraping page {page_num}: {url}\")\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è  Failed to retrieve page {page_num}. \"\n",
    "                      f\"Status code: {response.status_code}\")\n",
    "                continue\n",
    "            \n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            listings = soup.find_all('div', class_='listing-card')\n",
    "            print(f\"    ‚úì Found {len(listings)} listings on page {page_num}\")\n",
    "            \n",
    "            for listing in listings:\n",
    "                # Extracting Title, Price, Location\n",
    "                title_tag = listing.find('h2')\n",
    "                title = title_tag.get_text(strip=True) if title_tag else 'No title'\n",
    "                price_tag = listing.find('p', class_='text-xl font-bold leading-7 text-grey-900')\n",
    "                price = price_tag.get_text(strip=True) if price_tag else 'No price'\n",
    "                location_tag = listing.find('p', class_='ml-1 truncate text-sm font-normal capitalize text-grey-650')\n",
    "                location = location_tag.get_text(strip=True) if location_tag else 'No location'\n",
    "\n",
    "                # Extracting Bedrooms, Bathrooms, Size\n",
    "                bedrooms = bathrooms = size = 'N/A'\n",
    "                swiper_div = listing.find('div', class_='scrollable-list')\n",
    "                if swiper_div:\n",
    "                    slides = swiper_div.find_all('div', class_='swiper-slide')\n",
    "                    for slide in slides:\n",
    "                        text = slide.get_text(strip=True)\n",
    "                        if 'Bedroom' in text:\n",
    "                            bedrooms = text\n",
    "                        elif 'Bathroom' in text:\n",
    "                            bathrooms = text\n",
    "                        elif 'm¬≤' in text:\n",
    "                            size = text\n",
    "\n",
    "                properties.append({\n",
    "                    'Title': title,\n",
    "                    'Price': price,\n",
    "                    'Location': location,\n",
    "                    'Bedrooms': bedrooms,\n",
    "                    'Bathrooms': bathrooms,\n",
    "                    'Size': size\n",
    "                })\n",
    "            \n",
    "            if page_num < end_page:\n",
    "                time.sleep(1) # Be polite and wait 1 second between pages\n",
    "                \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"‚ùå Error scraping page {page_num}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    df = pd.DataFrame(properties)\n",
    "    print(f\"\\n‚úÖ Scraping complete! Total properties extracted: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING WEB SCRAPING PROCESS\")\n",
    "print(\"=\" * 60)\n",
    "df_all_pages = scrape_pages(start_page=1, end_page=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREVIEW OF SCRAPED DATA\")\n",
    "print(\"=\" * 60)\n",
    "display(df_all_pages.head(10))\n",
    "\n",
    "print(\"\\nüìä DATASET INFORMATION:\")\n",
    "print(f\"Total rows: {len(df_all_pages)}\")\n",
    "print(f\"Total columns: {len(df_all_pages.columns)}\")\n",
    "print(f\"\\nColumn names: {list(df_all_pages.columns)}\")\n",
    "print(f\"\\nData types:\\n{df_all_pages.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df_all_pages.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_price(price_str: str) -> float:\n",
    "    \"\"\"Converts price string (e.g., 'KSh 1,200,000') to a float.\"\"\"\n",
    "    if not price_str or price_str in ['No price', 'N/A', '']:\n",
    "        return np.nan\n",
    "    try:\n",
    "        clean_str = price_str.replace('KSh', '').strip()\n",
    "        clean_str = clean_str.replace(',', '')\n",
    "        return float(clean_str)\n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "def extract_number_from_text(text: str) -> float:\n",
    "    \"\"\"Extracts the first number from a string for bedrooms/bathrooms.\"\"\"\n",
    "    if not text or text in ['N/A', 'No data', '']:\n",
    "        return np.nan\n",
    "    if 'studio' in text.lower():\n",
    "        return 0.0\n",
    "    try:\n",
    "        match = re.search(r'\\d+', text)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "def clean_size(size_str: str) -> float:\n",
    "    \"\"\"Converts size string (e.g., '100 m¬≤') to a float in sq meters.\"\"\"\n",
    "    if not size_str or size_str in ['N/A', 'No size', '']:\n",
    "        return np.nan\n",
    "    try:\n",
    "        clean_str = size_str.replace('m¬≤', '').replace('m2', '').strip()\n",
    "        clean_str = clean_str.replace(',', '')\n",
    "        return float(clean_str)\n",
    "    except (ValueError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "def clean_location(location_str: str) -> str:\n",
    "    \"\"\"Standardizes location strings (title case, handles missing data).\"\"\"\n",
    "    if not location_str or location_str in ['No location', 'N/A', '']:\n",
    "        return 'Unknown'\n",
    "    return location_str.strip().title()\n",
    "\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Applies all cleaning functions and filters the resulting DataFrame.\"\"\"\n",
    "    print(\"\\nüßπ STARTING DATA CLEANING PROCESS...\")\n",
    "    print(\"=\" * 60)\n",
    "    df_clean = df.copy()\n",
    "    initial_rows = len(df_clean)\n",
    "    print(f\"Initial number of records: {initial_rows}\")\n",
    "\n",
    "    print(\"\\n1Ô∏è‚É£ Cleaning Price column...\")\n",
    "    df_clean['Price_Numeric'] = df_clean['Price'].apply(clean_price)\n",
    "    valid_prices = df_clean['Price_Numeric'].notna().sum()\n",
    "    print(f\"    ‚úì Converted {valid_prices}/{initial_rows} prices to numeric\")\n",
    "    \n",
    "    print(\"\\n2Ô∏è‚É£ Cleaning Bedrooms column...\")\n",
    "    df_clean['Bedrooms_Numeric'] = df_clean['Bedrooms'].apply(extract_number_from_text)\n",
    "    valid_bedrooms = df_clean['Bedrooms_Numeric'].notna().sum()\n",
    "    print(f\"    ‚úì Extracted {valid_bedrooms}/{initial_rows} bedroom counts\")\n",
    "\n",
    "    print(\"\\n3Ô∏è‚É£ Cleaning Bathrooms column...\")\n",
    "    df_clean['Bathrooms_Numeric'] = df_clean['Bathrooms'].apply(extract_number_from_text)\n",
    "    valid_bathrooms = df_clean['Bathrooms_Numeric'].notna().sum()\n",
    "    print(f\"    ‚úì Extracted {valid_bathrooms}/{initial_rows} bathroom counts\")\n",
    "    \n",
    "    print(\"\\n4Ô∏è‚É£ Cleaning Size column...\")\n",
    "    df_clean['Size_SqM'] = df_clean['Size'].apply(clean_size)\n",
    "    valid_sizes = df_clean['Size_SqM'].notna().sum()\n",
    "    print(f\"    ‚úì Extracted {valid_sizes}/{initial_rows} size values\")\n",
    "\n",
    "    print(\"\\n5Ô∏è‚É£ Cleaning Location column...\")\n",
    "    df_clean['Location_Clean'] = df_clean['Location'].apply(clean_location)\n",
    "    print(f\"    ‚úì Standardized all location names\")\n",
    "\n",
    "    print(\"\\n6Ô∏è‚É£ Removing incomplete records...\")\n",
    "    df_clean = df_clean.dropna(subset=['Price_Numeric', 'Bedrooms_Numeric'])\n",
    "    final_rows = len(df_clean)\n",
    "    removed_rows = initial_rows - final_rows\n",
    "    print(f\"    ‚úì Removed {removed_rows} records with missing critical data\")\n",
    "    print(f\"    ‚úì Final dataset: {final_rows} records\")\n",
    "\n",
    "    print(\"\\n7Ô∏è‚É£ Adding metadata columns...\")\n",
    "    df_clean['Scraped_Date'] = pd.Timestamp.now()\n",
    "    df_clean['Source'] = 'buyrentkenya.com'\n",
    "    print(f\"    ‚úì Added Scraped_Date and Source columns\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA CLEANING COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    return df_clean\n",
    "\n",
    "df_cleaned = clean_dataframe(df_all_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä CLEANED DATA PREVIEW:\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df_cleaned.head())\n",
    "\n",
    "print(\"\\nüîç COMPARISON: RAW vs CLEANED DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìã RAW DATA (first row):\")\n",
    "print(df_all_pages.iloc[0].to_string())\n",
    "\n",
    "print(\"\\n\\n‚ú® CLEANED DATA (first row):\\n\")\n",
    "print(df_cleaned.iloc[0].to_string())\n",
    "\n",
    "print(\"\\n\\nüìà DATA QUALITY SUMMARY:\")\n",
    "print(f\"Raw data columns: {len(df_all_pages.columns)}\")\n",
    "print(f\"Cleaned data columns: {len(df_cleaned.columns)}\")\n",
    "print(f\"\\nNew columns added: {set(df_cleaned.columns) - set(df_all_pages.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load: Database Integration (PostgreSQL via SQLAlchemy)\n",
    "\n",
    "**Note:** This section requires a running PostgreSQL instance with the specified database name (`house_prices`) created, and the credentials must be correct for successful execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Database Configuration ---\n",
    "DB_USERNAME = 'postgres'\n",
    "DB_PASSWORD = '7510'\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'house_prices'\n",
    "DATABASE_URL = f\"postgresql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "print(\"üîó Database Connection String Built:\")\n",
    "print(f\"    Connecting to: {DB_HOST}:{DB_PORT}\")\n",
    "print(f\"    Database: {DB_NAME}\")\n",
    "print(f\"    Username: {DB_USERNAME}\")\n",
    "print(\"    (Password hidden for security)\")\n",
    "\n",
    "print(\"\\nüîß Creating Database Engine...\")\n",
    "try:\n",
    "    engine = create_engine(DATABASE_URL, echo=False) # echo=True for verbose SQL logs\n",
    "    with engine.connect() as connection:\n",
    "        print(\"‚úÖ Successfully connected to PostgreSQL database!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to connect to database: {e}\")\n",
    "    print(\"\\nüí° TROUBLESHOOTING TIPS:\")\n",
    "    print(\"    1. Is PostgreSQL running? Check with: `sudo service postgresql status`\")\n",
    "    print(\"    2. Does the database exist? Create it with: `createdb house_prices`\")\n",
    "    print(\"    3. Are username/password/host correct?\")\n",
    "    # Stop execution if connection fails, as subsequent cells will fail\n",
    "    raise\n",
    "    \n",
    "# --- SQLAlchemy Model Definition ---\n",
    "Base = declarative_base()\n",
    "class HouseProperty(Base):\n",
    "    __tablename__ = 'properties'\n",
    "    \n",
    "    # Primary Key and Raw Data Columns\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    title = Column(Text, nullable=False)\n",
    "    price_text = Column(String(50))\n",
    "    location = Column(String(200))\n",
    "    bedrooms_text = Column(String(50))\n",
    "    bathrooms_text = Column(String(50))\n",
    "    size_text = Column(String(50))\n",
    "    \n",
    "    # Cleaned Data Columns\n",
    "    price_numeric = Column(Float)\n",
    "    bedrooms_numeric = Column(Integer)\n",
    "    bathrooms_numeric = Column(Integer)\n",
    "    size_sqm = Column(Float)\n",
    "    location_clean = Column(String(200))\n",
    "    \n",
    "    # Metadata\n",
    "    source = Column(String(100))\n",
    "    scraped_date = Column(DateTime)\n",
    "    inserted_date = Column(DateTime, default=datetime.utcnow)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Property(id={self.id}, title='{self.title[:30]}...', price={self.price_numeric})>\"\n",
    "        \n",
    "print(\"\\nüìã Database Schema Defined:\")\n",
    "print(f\"    Table Name: {HouseProperty.__tablename__}\")\n",
    "for column in HouseProperty.__table__.columns:\n",
    "    print(f\"      - {column.name}: {column.type}\")\n",
    "    \n",
    "# --- Create Table ---\n",
    "print(\"\\nüèóÔ∏è  Creating table in database (if it does not exist)...\")\n",
    "try:\n",
    "    Base.metadata.create_all(engine)\n",
    "    print(\"‚úÖ Table 'properties' ensured to exist successfully!\")\n",
    "    \n",
    "    # Verification check\n",
    "    inspector = inspect(engine)\n",
    "    if 'properties' in inspector.get_table_names():\n",
    "        columns = inspector.get_columns('properties')\n",
    "        print(f\"    Verified: Table exists with {len(columns)} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_db(df: pd.DataFrame) -> list:\n",
    "    \"\"\"Converts a pandas DataFrame into a list of SQLAlchemy HouseProperty objects.\"\"\"\n",
    "    print(f\"\\nüì¶ Preparing {len(df)} records for database insertion...\")\n",
    "    property_objects = []\n",
    "    for index, row in df.iterrows():\n",
    "        property_obj = HouseProperty(\n",
    "            title=row['Title'],\n",
    "            price_text=row['Price'],\n",
    "            location=row['Location'],\n",
    "            bedrooms_text=row['Bedrooms'],\n",
    "            bathrooms_text=row['Bathrooms'],\n",
    "            size_text=row['Size'],\n",
    "            price_numeric=row['Price_Numeric'] if pd.notna(row['Price_Numeric']) else None,\n",
    "            bedrooms_numeric=int(row['Bedrooms_Numeric']) if pd.notna(row['Bedrooms_Numeric']) else None,\n",
    "            bathrooms_numeric=int(row['Bathrooms_Numeric']) if pd.notna(row['Bathrooms_Numeric']) else None,\n",
    "            size_sqm=row['Size_SqM'] if pd.notna(row['Size_SqM']) else None,\n",
    "            location_clean=row['Location_Clean'],\n",
    "            source=row['Source'],\n",
    "            scraped_date=row['Scraped_Date']\n",
    "        )\n",
    "        property_objects.append(property_obj)\n",
    "    print(f\"‚úÖ Prepared {len(property_objects)} property objects\")\n",
    "    return property_objects\n",
    "\n",
    "property_records = prepare_data_for_db(df_cleaned)\n",
    "print(\"\\nüìã Example Property Object:\")\n",
    "print(property_records[0])\n",
    "\n",
    "def insert_data_to_db(property_objects: list, engine):\n",
    "    \"\"\"Inserts property objects into the database using SQLAlchemy sessions.\"\"\"\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    print(f\"\\nüíæ Inserting {len(property_objects)} records into database...\")\n",
    "    try:\n",
    "        session.add_all(property_objects)\n",
    "        session.commit()\n",
    "        print(f\"‚úÖ Successfully inserted {len(property_objects)} records!\")\n",
    "        return len(property_objects)\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"‚ùå Error inserting data: {e}\")\n",
    "        return 0\n",
    "    finally:\n",
    "        session.close()\n",
    "        \n",
    "records_inserted = insert_data_to_db(property_records, engine)\n",
    "print(f\"\\nüìä DATABASE INSERTION SUMMARY:\")\n",
    "print(f\"    Total records processed: {len(df_cleaned)}\")\n",
    "print(f\"    Successfully inserted: {records_inserted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîç VERIFYING DATA IN DATABASE...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query 1: Top 5 Records\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        id, \n",
    "        title, \n",
    "        price_numeric, \n",
    "        bedrooms_numeric, \n",
    "        bathrooms_numeric, \n",
    "        location_clean, \n",
    "        scraped_date\n",
    "    FROM properties\n",
    "    ORDER BY id DESC -- Show the most recently inserted data first\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "verification_data = pd.read_sql(query, engine)\n",
    "print(\"Top 5 Most Recently Inserted Records:\")\n",
    "display(verification_data)\n",
    "\n",
    "print(\"\\nüìä DATABASE STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Query 2: Average Price\n",
    "avg_price_query = \"\"\"\n",
    "    SELECT AVG(price_numeric) as avg_price\n",
    "    FROM properties\n",
    "    WHERE price_numeric IS NOT NULL\n",
    "\"\"\"\n",
    "avg_price = pd.read_sql(avg_price_query, engine)\n",
    "print(f\"    Average Price (All Data): KSh {avg_price['avg_price'].iloc[0]:,.2f}\")\n",
    "\n",
    "# Query 3: Price Range\n",
    "price_range_query = \"\"\"\n",
    "    SELECT \n",
    "        MIN(price_numeric) as min_price, \n",
    "        MAX(price_numeric) as max_price\n",
    "    FROM properties\n",
    "    WHERE price_numeric IS NOT NULL\n",
    "\"\"\"\n",
    "price_range = pd.read_sql(price_range_query, engine)\n",
    "print(f\"    Cheapest: KSh {price_range['min_price'].iloc[0]:,.2f}\")\n",
    "print(f\"    Most Expensive: KSh {price_range['max_price'].iloc[0]:,.2f}\")\n",
    "\n",
    "# Query 4: Bedroom Distribution\n",
    "bedroom_dist_query = \"\"\"\n",
    "    SELECT \n",
    "        bedrooms_numeric,\n",
    "        COUNT(*) as count\n",
    "    FROM properties\n",
    "    WHERE bedrooms_numeric IS NOT NULL\n",
    "    GROUP BY bedrooms_numeric\n",
    "    ORDER BY bedrooms_numeric\n",
    "\"\"\"\n",
    "bedroom_dist = pd.read_sql(bedroom_dist_query, engine)\n",
    "print(f\"\\nüõèÔ∏è  Bedroom Distribution (All Data):\")\n",
    "display(bedroom_dist)\n",
    "\n",
    "# Query 5: Top 5 Locations\n",
    "location_dist_query = \"\"\"\n",
    "    SELECT \n",
    "        location_clean,\n",
    "        COUNT(*) as count\n",
    "    FROM properties\n",
    "    GROUP BY location_clean\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "location_dist = pd.read_sql(location_dist_query, engine)\n",
    "print(f\"\\nüìç Top 5 Locations (All Data):\")\n",
    "display(location_dist)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ STEP 3: DATABASE STORAGE COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
